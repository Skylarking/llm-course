{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 一、简介\n",
    "- 参考：(https://huggingface.co/blog/zh/chat-templates)\n",
    "\n",
    "## 1. 为什么哟啊使用chat模版？\n",
    "在使用hugging-face库时，我们加载Tokenizer和model都是使用同一个模型的相关信息，如下所示：\n",
    "```\n",
    "# 加载同一个checkpoint的Tokenizer和model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "```\n",
    "如果Tokenizer和model加载的不是同一个checkpoint，那么最坏的情况下在编码chat prompt时，某些token id不在训练时的token中，相当于ood了。就算在，也有可能id不是同一个，也有分布偏移的问题。\n",
    "\n",
    "## 2. 不同的chat prompt模版\n",
    "一般的chat prompt会有role和content。role分别有：\n",
    "- user：用于发送消息\n",
    "- assistant：用于模型生成回答\n",
    "- system：在对话开始时给出高级指令\n",
    "一般用一个字典表示一条消息（message），多条message组合成一个列表表示一个对话（dialog）\n",
    "```\n",
    "[\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Nice to meet you!\"}\n",
    "]\n",
    "```\n",
    "那么转换成prompt可能多种多样：\n",
    "- 即时消息型\n",
    "```\n",
    "User: Hey there!\n",
    "Bot: Nice to meet you!\n",
    "```\n",
    "- 添加特殊token指代role\n",
    "```\n",
    "[USER] Hey there! [/USER]\n",
    "[ASST] Nice to meet you! [/ASST]\n",
    "```\n",
    "- 添加特殊token切分边界\n",
    "```\n",
    "<|im_start|>user\n",
    "Hey there!<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Nice to meet you!<|im_end|>\n",
    "```\n",
    "\n",
    "# 二、Chat Templates：一种保存格式信息的方式\n",
    "- 主要是存格式\n",
    "- 用的是[jinja模版字符串](https://jinja.palletsprojects.com/en/3.1.x/)\n",
    "\n",
    "## 1. jinja模版\n",
    "上述三种chat格式对应下面三种jinja模版：\n",
    "- 即时消息型\n",
    "```\n",
    "{% for message in messages %}\n",
    "    {% if message['role'] == 'user' %}\n",
    "        {{ \"User : \" }}\n",
    "    {% else %}\n",
    "        {{ \"Bot : \" }}\n",
    "    {{ message['content'] + '\\n' }}\n",
    "{% endfor %}\n",
    "```\n",
    "- 添加特殊token指代role\n",
    "```\n",
    "{% for message in messages %}\n",
    "    {% if message['role'] == 'user' %}\n",
    "        {{ \"[USER]\" + message['content'] + \" [/USER]\" }}\n",
    "    {% else %}\n",
    "        {{ \"[ASST]\" + message['content'] + \" [/ASST]\" }}\n",
    "    {{ message['content'] + '\\n' }}\n",
    "{% endfor %}\n",
    "```\n",
    "- 添加特殊token切分边界\n",
    "```\n",
    "\"{% for message in messages %}\"\n",
    "    \"{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}\"\n",
    "\"{% endfor %}\"\n",
    "```\n",
    "\n",
    "## 2. 为什么使用jinja模版？\n",
    "- 因为目前各个LLM使用不同的模版训练，而且很难统一起来\n",
    "- 因为它能够用统一的语言编码我们目前所有使用的chat prompt模版\n",
    "- hugging-face很好的集成了chat_template相关方法\n",
    "\n",
    "# 3. 如何使用模版？\n",
    "可以查看[开发指南](https://huggingface.co/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.apply_chat_template)\n",
    "\n",
    "虽然默认提供一套模版，但是最好是显式指定模版：\n",
    "```\n",
    "tokenizer.chat_template = \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}\"\n",
    "\n",
    "```\n",
    "\n",
    "另外在开发自己的LLM，最好将jinja的chat模版上传，并提交PR"
   ],
   "id": "f6d08f675ae870e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

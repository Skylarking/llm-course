{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 一、 简介\n",
    "- 参考：https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt\n",
    "## 1. 什么是Causal Language Model(CLM)？\n",
    "这个概念可以和Mask Language model(MLM)进行对比：\n",
    "- MLM：是将某些token随机替换为[MASK]这一个token；训练时，除了被MASK的token外，其他所有token都能看到，没有先后顺序；代表模型是Bert\n",
    "```\n",
    "The goal of life is [Mask].  （注意[MASK]后还有一个“.”token）\n",
    "\n",
    "[MASK]: [life: 0.109, survival: 0.039, ....] \n",
    "```\n",
    "- CLM：是一种自回归模型；有先后顺序，对于当前token，相当于当前以及之后的所有token都被mask了；代表模型是GPT2\n",
    "```\n",
    "My name is Sylvain and I like to\n",
    "\n",
    "My name is Sylvain and I like to talk about music and comics and film. ....\n",
    "```\n",
    "\n",
    "MLM和CLM共同点都是自监督模型（无监督），而Translation Language Modeling (TLM，翻译语言模型)是监督模型，需要标注数据。CLM也是一种Decoder-only的LLM，即Transformer架构中，相当于只有Decoder，没有Encoder（区别于Bert）。MLM、CLM、TLM都属于生成式模型。\n",
    "\n",
    "按照目前的趋势，目前的LLM的含义更接近于CLM，因此不管是pre-train LLM和post-train LLM，通常都指代的是CLM。\n",
    "\n",
    "由于有强烈的先后关系的因果关系，因此能够很好的用来做代码生成、音符生成、文章生成等任务。本章微调一个CLM来做code generation\n",
    "\n"
   ],
   "id": "94a116f63cf48297"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T02:43:24.552893Z",
     "start_time": "2024-09-03T02:43:24.548888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# 获取当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "print(\"当前工作目录:\", current_directory)\n",
    "\n",
    "# 设置新的工作目录\n",
    "new_directory = \"/mnt/d/code/llm/llm-course\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# 再次获取当前工作目录，确认是否更改成功\n",
    "current_directory = os.getcwd()\n",
    "print(\"新的工作目录:\", current_directory)"
   ],
   "id": "93b0a267afa6fd92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /mnt/d/code/llm/llm-course/mynotes\n",
      "新的工作目录: /mnt/d/code/llm/llm-course\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 二、 微调CLM得到一个code generation model\n",
    "\n",
    "本节只考虑python代码，并且只考虑python代码的子集，包含了matplotlib, seaborn, pandas, scikit-learn这几个库\n",
    "\n",
    "## 1. 获取数据\n",
    "数据集使用的是[codeparrot](https://huggingface.co/datasets/transformersbook/codeparrot),\n",
    "由于只训练python代码子集，因此需要对codeparrot数据集过滤。\n",
    "\n",
    "### (1) python代码子集数据过滤"
   ],
   "id": "f39b40ee66a7c39f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T02:43:33.341423Z",
     "start_time": "2024-09-03T02:43:33.338669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对codeparrot数据集过滤，只包含matplotlib, seaborn, pandas, scikit-learn这几个库的数据\n",
    "def any_keyword_in_string(string, keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword in string:\n",
    "            return True\n",
    "    return False"
   ],
   "id": "bad72a6574d35726",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T02:43:34.990125Z",
     "start_time": "2024-09-03T02:43:34.986510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 过滤样例\n",
    "filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
    "example_1 = \"import numpy as np\"    # 过滤掉\n",
    "example_2 = \"import pandas as pd\"   # 保留\n",
    "\n",
    "print(\n",
    "    any_keyword_in_string(example_1, filters), any_keyword_in_string(example_2, filters)\n",
    ")"
   ],
   "id": "6bbcbca6fe5e5ad4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T02:48:35.487364Z",
     "start_time": "2024-09-03T02:48:32.553204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "# 流式过滤数据集\n",
    "def filter_streaming_dataset(dataset, filters):\n",
    "    filtered_dict = defaultdict(list)\n",
    "    total = 0\n",
    "    for sample in tqdm(iter(dataset)):\n",
    "        total += 1\n",
    "        if any_keyword_in_string(sample[\"content\"], filters):\n",
    "            for k, v in sample.items():\n",
    "                filtered_dict[k].append(v)\n",
    "    print(f\"{len(filtered_dict['content'])/total:.2%} of data after filtering.\")\n",
    "    return Dataset.from_dict(filtered_dict)"
   ],
   "id": "c990492c398609ba",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "进行数据过滤",
   "id": "5214e1237d76e2a8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-03T02:49:29.892438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据过滤\n",
    "# This cell will take a very long time to execute, so you should skip it and go to\n",
    "# the next one!\n",
    "from datasets import load_dataset\n",
    "\n",
    "split = \"train\"  # \"valid\"\n",
    "filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
    "\n",
    "data = load_dataset(f\"transformersbook/codeparrot-{split}\", split=split, streaming=True)"
   ],
   "id": "ec073f45c17906d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f53e9c557a3a4a8eb6929867b0bfb9da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ff87a5bdf394cbeb2a4339504fabc83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18593791it [8:28:09, 609.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.26% of data after filtering.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T02:06:40.189407Z",
     "start_time": "2024-09-06T02:06:40.074096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 过滤数据\n",
    "filtered_data = filter_streaming_dataset(data, filters)"
   ],
   "id": "ce57a56d78344cdb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_streaming_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m filtered_data \u001B[38;5;241m=\u001B[39m \u001B[43mfilter_streaming_dataset\u001B[49m(data, filters)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'filter_streaming_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (2) 过滤后的数据集加载",
   "id": "29c6e1fe747596cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")\n",
    "ds_valid = load_dataset(\"huggingface-course/codeparrot-ds-valid\", split=\"validation\")\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train.shuffle().select(range(50000)),  # 数据集shuffle并减小样本数\n",
    "        \"valid\": ds_valid.shuffle().select(range(500))\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ],
   "id": "731fcb8e1fa4bbd7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
